{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.10\n"
     ]
    }
   ],
   "source": [
    "%cd TTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using a default docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-07 08:17:06 Starting - Starting the training job...\n",
      "2022-06-07 08:17:31 Starting - Preparing the instances for trainingProfilerReport-1654589826: InProgress\n",
      ".........\n",
      "2022-06-07 08:19:03 Downloading - Downloading input data...\n",
      "2022-06-07 08:19:31 Training - Downloading the training image.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-06-07 08:20:16,779 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-06-07 08:20:16,781 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-07 08:20:16,791 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-06-07 08:20:16,796 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\n",
      "2022-06-07 08:20:32 Training - Training image download completed. Training in progress.\u001b[34m2022-06-07 08:20:35,643 sagemaker-training-toolkit INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34m  Installing build dependencies: started\u001b[0m\n",
      "\u001b[34m  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34m  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.7.1)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow==2.3.1\n",
      "  Downloading tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4 MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy==1.17.5\n",
      "  Using cached numpy-1.17.5-cp36-cp36m-manylinux1_x86_64.whl (20.0 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.2.2)\u001b[0m\n",
      "\u001b[34mCollecting numba==0.48\n",
      "  Downloading numba-0.48.0-1-cp36-cp36m-manylinux2014_x86_64.whl (3.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting librosa==0.7.2\n",
      "  Downloading librosa-0.7.2.tar.gz (1.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting phonemizer>=2.2.0\n",
      "  Downloading phonemizer-3.2.0-py3-none-any.whl (90 kB)\u001b[0m\n",
      "\u001b[34mCollecting unidecode==0.4.20\u001b[0m\n",
      "\u001b[34m  Downloading Unidecode-0.04.20-py2.py3-none-any.whl (228 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboardX\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (3.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (8.2.0)\u001b[0m\n",
      "\u001b[34mCollecting flask\n",
      "  Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (4.59.0)\u001b[0m\n",
      "\u001b[34mCollecting inflect\n",
      "  Downloading inflect-5.3.0-py3-none-any.whl (32 kB)\u001b[0m\n",
      "\u001b[34mCollecting bokeh==1.4.0\n",
      "  Downloading bokeh-1.4.0.tar.gz (32.4 MB)\u001b[0m\n",
      "\u001b[34mCollecting pysbd\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyworld\n",
      "  Downloading pyworld-0.3.0.tar.gz (212 kB)\n",
      "  Installing build dependencies: started\u001b[0m\n",
      "\u001b[34m  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\u001b[0m\n",
      "\u001b[34m    Preparing wheel metadata: finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.46.3-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\u001b[0m\n",
      "\u001b[34mCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34mCollecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (3.17.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (0.36.2)\u001b[0m\n",
      "\u001b[34mCollecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.14.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (74 kB)\u001b[0m\n",
      "\u001b[34mCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.7.0\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[34mCollecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting llvmlite<0.32.0,>=0.31.0dev0\n",
      "  Downloading llvmlite-0.31.0-cp36-cp36m-manylinux1_x86_64.whl (20.2 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from numba==0.48->-r requirements.txt (line 5)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mCollecting audioread>=2.0.0\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.6/site-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (4.4.2)\u001b[0m\n",
      "\u001b[34mCollecting resampy>=0.2.2\n",
      "  Downloading resampy-0.2.2.tar.gz (323 kB)\u001b[0m\n",
      "\u001b[34mCollecting soundfile>=0.9.0\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.6/site-packages (from bokeh==1.4.0->-r requirements.txt (line 15)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from bokeh==1.4.0->-r requirements.txt (line 15)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2>=2.7 in /opt/conda/lib/python3.6/site-packages (from bokeh==1.4.0->-r requirements.txt (line 15)) (3.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.6/site-packages (from bokeh==1.4.0->-r requirements.txt (line 15)) (20.9)\u001b[0m\n",
      "\u001b[34mCollecting tornado>=4.3\n",
      "  Downloading tornado-6.1-cp36-cp36m-manylinux2010_x86_64.whl (427 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch>=1.5->-r requirements.txt (line 1)) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch>=1.5->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mCollecting segments\n",
      "  Downloading segments-2.2.0-py2.py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=18.1 in /opt/conda/lib/python3.6/site-packages (from phonemizer>=2.2.0->-r requirements.txt (line 7)) (21.2.0)\u001b[0m\n",
      "\u001b[34mCollecting dlinfo\n",
      "  Downloading dlinfo-1.2.1-py3-none-any.whl (3.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.7->bokeh==1.4.0->-r requirements.txt (line 15)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=16.8->bokeh==1.4.0->-r requirements.txt (line 15)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.7.2->-r requirements.txt (line 6)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.6/site-packages (from soundfile>=0.9.0->librosa==0.7.2->-r requirements.txt (line 6)) (1.14.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2->-r requirements.txt (line 6)) (2.20)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (2.25.1)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (4.0.0)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 10)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.6/site-packages (from flask->-r requirements.txt (line 12)) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cython>=0.24.0 in /opt/conda/lib/python3.6/site-packages (from pyworld->-r requirements.txt (line 17)) (0.29.21)\u001b[0m\n",
      "\u001b[34mCollecting clldutils>=1.7.3\n",
      "  Downloading clldutils-3.12.0-py2.py3-none-any.whl (197 kB)\u001b[0m\n",
      "\u001b[34mCollecting regex\n",
      "  Downloading regex-2022.6.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\u001b[0m\n",
      "\u001b[34mCollecting csvw>=1.5.6\n",
      "  Downloading csvw-2.0.0-py2.py3-none-any.whl (35 kB)\u001b[0m\n",
      "\u001b[34mCollecting colorlog\n",
      "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.6/site-packages (from clldutils>=1.7.3->segments->phonemizer>=2.2.0->-r requirements.txt (line 7)) (0.8.9)\u001b[0m\n",
      "\u001b[34mCollecting uritemplate>=3.0.0\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting isodate\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\u001b[0m\n",
      "\u001b[34mCollecting rfc3986<2\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: TTS, librosa, bokeh, audioread, resampy, termcolor, pyworld\n",
      "  Building wheel for TTS (PEP 517): started\u001b[0m\n",
      "\u001b[34m  Building wheel for TTS (PEP 517): finished with status 'done'\n",
      "  Created wheel for TTS: filename=TTS-0.0.9.2-cp36-cp36m-linux_x86_64.whl size=550897 sha256=786a15a8804e672ad244587d044f8718f01b759cc36c61d6b416f84d0d0578b9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-a_q98d03/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\n",
      "  Building wheel for librosa (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for librosa (setup.py): finished with status 'done'\n",
      "  Created wheel for librosa: filename=librosa-0.7.2-py3-none-any.whl size=1612883 sha256=8a7e4657b0adb9c039727e52181540abb89b463d62285c65f8f240cd295dc4f7\n",
      "  Stored in directory: /root/.cache/pip/wheels/cb/1d/15/a479fa740849128d481333d2f354f97691be3e2c82480a3e00\n",
      "  Building wheel for bokeh (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for bokeh (setup.py): finished with status 'done'\n",
      "  Created wheel for bokeh: filename=bokeh-1.4.0-py3-none-any.whl size=23689200 sha256=7086595a8a09ce3dcd98452254f81a1643f4ac07dc01971be8c1e2fbf867cc45\n",
      "  Stored in directory: /root/.cache/pip/wheels/b6/72/72/a6a223f72a9b02a4922a3c2fec55b2f65567254d398f6c5f74\n",
      "  Building wheel for audioread (setup.py): started\n",
      "  Building wheel for audioread (setup.py): finished with status 'done'\n",
      "  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23141 sha256=1466b5bd91c5a19892e3c43c768b76e3ebf9bc6cd2023b353dd01244ab1c2626\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/14/0a/863e4ed680b3204444cf486733e609d7ff7abe8fceafab67dc\n",
      "  Building wheel for resampy (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for resampy (setup.py): finished with status 'done'\n",
      "  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320718 sha256=e53f25192b2b7cdd47703b65e9970c68ff047a098e1d68e3b51ede35a2524ac4\n",
      "  Stored in directory: /root/.cache/pip/wheels/cf/d4/04/49d8824a42bd9f9b11d502727965b9997f0d41d2b22ae4f645\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=58a6214af1cf48a49268a5c867829e1d3d855845806c9c1c80d0facfb1a5e514\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for pyworld (PEP 517): started\u001b[0m\n",
      "\u001b[34m  Building wheel for pyworld (PEP 517): finished with status 'done'\n",
      "  Created wheel for pyworld: filename=pyworld-0.3.0-cp36-cp36m-linux_x86_64.whl size=663807 sha256=77cb3f1b6220032adb5b29abf3c30d13a41d673b9d2e75fad3385c737beacc16\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/ce/09/0dc35ecfbaf36d8f95b00aa2c5f1648d44e49ce7f56772756f\u001b[0m\n",
      "\u001b[34mSuccessfully built TTS librosa bokeh audioread resampy termcolor pyworld\u001b[0m\n",
      "\u001b[34mInstalling collected packages: uritemplate, rfc3986, pyasn1-modules, oauthlib, isodate, cachetools, requests-oauthlib, numpy, llvmlite, importlib-metadata, google-auth, csvw, colorlog, tensorboard-plugin-wit, tensorboard-data-server, regex, numba, markdown, grpcio, google-auth-oauthlib, clldutils, absl-py, wrapt, tornado, termcolor, tensorflow-estimator, tensorboard, soundfile, segments, resampy, opt-einsum, keras-preprocessing, itsdangerous, h5py, gast, dlinfo, audioread, astunparse, unidecode, tensorflow, tensorboardX, pyworld, pysbd, phonemizer, librosa, inflect, flask, bokeh, TTS\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.0.1\n",
      "    Uninstalling importlib-metadata-4.0.1:\n",
      "      Successfully uninstalled importlib-metadata-4.0.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.8.0\n",
      "    Uninstalling h5py-2.8.0:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled h5py-2.8.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed TTS-0.0.9.2 absl-py-1.1.0 astunparse-1.6.3 audioread-2.1.9 bokeh-1.4.0 cachetools-4.2.4 clldutils-3.12.0 colorlog-6.6.0 csvw-2.0.0 dlinfo-1.2.1 flask-2.0.3 gast-0.3.3 google-auth-2.6.6 google-auth-oauthlib-0.4.6 grpcio-1.46.3 h5py-2.10.0 importlib-metadata-4.8.3 inflect-5.3.0 isodate-0.6.1 itsdangerous-2.0.1 keras-preprocessing-1.1.2 librosa-0.7.2 llvmlite-0.31.0 markdown-3.3.7 numba-0.48.0 numpy-1.17.5 oauthlib-3.2.0 opt-einsum-3.3.0 phonemizer-3.2.0 pyasn1-modules-0.2.8 pysbd-0.3.4 pyworld-0.3.0 regex-2022.6.2 requests-oauthlib-1.3.1 resampy-0.2.2 rfc3986-1.5.0 segments-2.2.0 soundfile-0.10.3.post1 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorboardX-2.5.1 tensorflow-2.3.1 tensorflow-estimator-2.3.0 termcolor-1.1.0 tornado-6.1 unidecode-0.4.20 uritemplate-4.1.1 wrapt-1.14.1\u001b[0m\n",
      "\u001b[34m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-06-07 08:21:59,505 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-07 08:21:59,518 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-07 08:21:59,531 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-07 08:21:59,542 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config_path\": \"./config.json\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-06-07-08-14-19-030\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-082780074557/pytorch-training-2022-06-07-08-14-19-030/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_test\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_test.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"config_path\":\"./config.json\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_test.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_test\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-082780074557/pytorch-training-2022-06-07-08-14-19-030/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config_path\":\"./config.json\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-06-07-08-14-19-030\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-082780074557/pytorch-training-2022-06-07-08-14-19-030/source/sourcedir.tar.gz\",\"module_name\":\"train_test\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_test.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--config_path\",\"./config.json\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_CONFIG_PATH=./config.json\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m train_test --config_path ./config.json\u001b[0m\n",
      "\u001b[34mAAAAA /opt/ml/code AAAAA\u001b[0m\n",
      "\u001b[34mCODE_OF_CONDUCT.md\u001b[0m\n",
      "\u001b[34mCODE_OWNERS.rst\u001b[0m\n",
      "\u001b[34mCONTRIBUTING.md\u001b[0m\n",
      "\u001b[34mLICENSE.txt\u001b[0m\n",
      "\u001b[34mMANIFEST.in\u001b[0m\n",
      "\u001b[34mREADME.md\u001b[0m\n",
      "\u001b[34mTTS\u001b[0m\n",
      "\u001b[34mTTS.egg-info\u001b[0m\n",
      "\u001b[34mUntitled.ipynb\u001b[0m\n",
      "\u001b[34mbuild\u001b[0m\n",
      "\u001b[34mconfig.json\u001b[0m\n",
      "\u001b[34mcore.14379\u001b[0m\n",
      "\u001b[34mdist\u001b[0m\n",
      "\u001b[34mfind_missing_req.ipynb\u001b[0m\n",
      "\u001b[34mimages\u001b[0m\n",
      "\u001b[34mlaunch_train.ipynb\u001b[0m\n",
      "\u001b[34mnotebooks\u001b[0m\n",
      "\u001b[34mpreprocess_tacotron.py\u001b[0m\n",
      "\u001b[34mpreprocessor_SM.ipynb\u001b[0m\n",
      "\u001b[34mpyproject.toml\u001b[0m\n",
      "\u001b[34mrequirements.txt\u001b[0m\n",
      "\u001b[34mrequirements_saved.txt\u001b[0m\n",
      "\u001b[34mrun_tests.sh\u001b[0m\n",
      "\u001b[34mrun_tts_SM.ipynb\u001b[0m\n",
      "\u001b[34mrun_tts_sagemaker.ipynb\u001b[0m\n",
      "\u001b[34mserver\u001b[0m\n",
      "\u001b[34msetup.cfg\u001b[0m\n",
      "\u001b[34msetup.py\u001b[0m\n",
      "\u001b[34mtests\u001b[0m\n",
      "\u001b[34mtrain_tacotron.py\u001b[0m\n",
      "\u001b[34mtrain_test.py\u001b[0m\n",
      "\u001b[34mtrainin\u001b[0m\n",
      "\u001b[34mtraining.log\u001b[0m\n",
      "\u001b[34mversion.py\u001b[0m\n",
      "\u001b[34mAAAAA 0 AAAAA\u001b[0m\n",
      "\u001b[34mdone\u001b[0m\n",
      "\u001b[34msh: 1: !apt-get: not found\u001b[0m\n",
      "\u001b[34m2022-06-07 08:22:01,354 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-06-07 08:22:32 Uploading - Uploading generated training model\n",
      "2022-06-07 08:22:32 Completed - Training job completed\n",
      "ProfilerReport-1654589826: NoIssuesFound\n",
      "Training seconds: 193\n",
      "Billable seconds: 193\n"
     ]
    }
   ],
   "source": [
    "ROLE = get_execution_role()\n",
    "INSTANCE = 'ml.m5.4xlarge'\n",
    "config = \"./config.json\"\n",
    "\n",
    "pytorch_estimator = PyTorch(entry_point='train_test.py',\n",
    "                            source_dir=\"./\",\n",
    "                            framework_version=\"1.7.1\",\n",
    "                            py_version=\"py3\",\n",
    "                            instance_type=INSTANCE,\n",
    "                            instance_count=1,\n",
    "                            role = ROLE,\n",
    "                            hyperparameters = {'config_path' : config}\n",
    "                           )\n",
    "\n",
    "pytorch_estimator.fit()\n",
    "\n",
    "# If the source_dir parameter is commented, the files of the current path are not copied inside the instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-17 16:02:36 Starting - Starting the training job...\n",
      "2022-05-17 16:03:00 Starting - Preparing the instances for trainingProfilerReport-1652803356: InProgress\n",
      ".........\n",
      "2022-05-17 16:04:20 Downloading - Downloading input data\n",
      "2022-05-17 16:04:20 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-05-17 16:04:51,055 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-05-17 16:04:51,057 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-17 16:04:51,067 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-05-17 16:04:51,072 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-05-17 16:04:51,378 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-17 16:04:51,391 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-17 16:04:51,403 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-17 16:04:51,413 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config_path\": \"./config.json\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-05-17-16-02-36-545\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-082780074557/pytorch-training-2022-05-17-16-02-36-545/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_test\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_test.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"config_path\":\"./config.json\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_test.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_test\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-082780074557/pytorch-training-2022-05-17-16-02-36-545/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config_path\":\"./config.json\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-05-17-16-02-36-545\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-082780074557/pytorch-training-2022-05-17-16-02-36-545/source/sourcedir.tar.gz\",\"module_name\":\"train_test\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_test.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--config_path\",\"./config.json\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_CONFIG_PATH=./config.json\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_test.py --config_path ./config.json\u001b[0m\n",
      "\u001b[34mAAAAA Namespace(config_path='./config.json') AAAAA\u001b[0m\n",
      "\u001b[34m2022-05-17 16:04:52,595 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-05-17 16:05:05 Uploading - Uploading generated training model\n",
      "2022-05-17 16:05:05 Completed - Training job completed\n",
      "Training seconds: 57\n",
      "Billable seconds: 57\n"
     ]
    }
   ],
   "source": [
    "# Training with input data this time...\n",
    "inputs = 's3://benitoin-buckettest/TTS/LJSpeech-1.1/wavs/'\n",
    "pytorch_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change of framework_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-07 09:46:53 Starting - Starting the training job...\n",
      "2022-06-07 09:47:17 Starting - Preparing the instances for trainingProfilerReport-1654595213: InProgress\n",
      "......\n",
      "2022-06-07 09:48:17 Downloading - Downloading input data...\n",
      "2022-06-07 09:48:37 Training - Downloading the training image.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/paramiko/transport.py:236: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\u001b[0m\n",
      "\u001b[34m2022-06-07 09:49:28,975 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-06-07 09:49:28,978 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-07 09:49:28,985 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-06-07 09:49:28,990 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\n",
      "2022-06-07 09:49:37 Training - Training image download completed. Training in progress.\u001b[34m2022-06-07 09:49:46,985 sagemaker-training-toolkit INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.11.0+cpu)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow==2.3.1\u001b[0m\n",
      "\u001b[34mDownloading tensorflow-2.3.1-cp38-cp38-manylinux2010_x86_64.whl (320.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 320.5/320.5 MB 4.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting numpy==1.17.5\u001b[0m\n",
      "\u001b[34mUsing cached numpy-1.17.5-cp38-cp38-manylinux1_x86_64.whl (20.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.8.0)\u001b[0m\n",
      "\u001b[34mCollecting numba==0.48\u001b[0m\n",
      "\u001b[34mDownloading numba-0.48.0-1-cp38-cp38-manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 100.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting librosa==0.7.2\u001b[0m\n",
      "\u001b[34mDownloading librosa-0.7.2.tar.gz (1.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 88.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting phonemizer>=2.2.0\u001b[0m\n",
      "\u001b[34mDownloading phonemizer-3.2.0-py3-none-any.whl (90 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 KB 18.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting unidecode==0.4.20\u001b[0m\n",
      "\u001b[34mDownloading Unidecode-0.04.20-py2.py3-none-any.whl (228 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 228.3/228.3 KB 41.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboardX\u001b[0m\n",
      "\u001b[34mDownloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.4/125.4 KB 18.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (3.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (9.1.0)\u001b[0m\n",
      "\u001b[34mCollecting flask\u001b[0m\n",
      "\u001b[34mDownloading Flask-2.1.2-py3-none-any.whl (95 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.2/95.2 KB 21.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (4.64.0)\u001b[0m\n",
      "\u001b[34mCollecting inflect\u001b[0m\n",
      "\u001b[34mDownloading inflect-5.6.0-py3-none-any.whl (33 kB)\u001b[0m\n",
      "\u001b[34mCollecting bokeh==1.4.0\u001b[0m\n",
      "\u001b[34mDownloading bokeh-1.4.0.tar.gz (32.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 32.4/32.4 MB 55.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting pysbd\u001b[0m\n",
      "\u001b[34mDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.1/71.1 KB 15.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pyworld\u001b[0m\n",
      "\u001b[34mDownloading pyworld-0.3.0.tar.gz (212 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.0/212.0 KB 35.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting h5py<2.11.0,>=2.10.0\u001b[0m\n",
      "\u001b[34mDownloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 102.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.7.0\u001b[0m\n",
      "\u001b[34mDownloading absl_py-1.1.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.7/123.7 KB 11.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard<3,>=2.3.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 122.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-estimator<2.4.0,>=2.3.0\u001b[0m\n",
      "\u001b[34mDownloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 459.0/459.0 KB 49.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting wrapt>=1.11.1\u001b[0m\n",
      "\u001b[34mDownloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.0/81.0 KB 15.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting astunparse==1.6.3\u001b[0m\n",
      "\u001b[34mDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (0.37.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (3.20.1)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.8.6\u001b[0m\n",
      "\u001b[34mDownloading grpcio-1.46.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 113.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting opt-einsum>=2.3.2\u001b[0m\n",
      "\u001b[34mDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 KB 16.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting gast==0.3.3\u001b[0m\n",
      "\u001b[34mDownloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting keras-preprocessing<1.2,>=1.1.1\u001b[0m\n",
      "\u001b[34mDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.6/42.6 KB 9.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting termcolor>=1.1.0\u001b[0m\n",
      "\u001b[34mDownloading termcolor-1.1.0.tar.gz (3.9 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting llvmlite<0.32.0,>=0.31.0dev0\u001b[0m\n",
      "\u001b[34mDownloading llvmlite-0.31.0-cp38-cp38-manylinux1_x86_64.whl (20.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.2/20.2 MB 82.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from numba==0.48->-r requirements.txt (line 5)) (62.1.0)\u001b[0m\n",
      "\u001b[34mCollecting audioread>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading audioread-2.1.9.tar.gz (377 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 377.5/377.5 KB 44.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (1.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.8/site-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (5.1.1)\u001b[0m\n",
      "\u001b[34mCollecting resampy>=0.2.2\u001b[0m\n",
      "\u001b[34mDownloading resampy-0.2.2.tar.gz (323 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 323.4/323.4 KB 23.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting soundfile>=0.9.0\u001b[0m\n",
      "\u001b[34mDownloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.8/site-packages (from bokeh==1.4.0->-r requirements.txt (line 15)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from bokeh==1.4.0->-r requirements.txt (line 15)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2>=2.7 in /opt/conda/lib/python3.8/site-packages (from bokeh==1.4.0->-r requirements.txt (line 15)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.8/site-packages (from bokeh==1.4.0->-r requirements.txt (line 15)) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tornado>=4.3 in /opt/conda/lib/python3.8/site-packages (from bokeh==1.4.0->-r requirements.txt (line 15)) (6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.5->-r requirements.txt (line 1)) (4.2.0)\u001b[0m\n",
      "\u001b[34mCollecting dlinfo\u001b[0m\n",
      "\u001b[34mDownloading dlinfo-1.2.1-py3-none-any.whl (3.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting segments\u001b[0m\n",
      "\u001b[34mDownloading segments-2.2.0-py2.py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=18.1 in /opt/conda/lib/python3.8/site-packages (from phonemizer>=2.2.0->-r requirements.txt (line 7)) (20.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 10)) (0.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 10)) (3.0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 10)) (4.33.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=8.0 in /opt/conda/lib/python3.8/site-packages (from flask->-r requirements.txt (line 12)) (8.1.3)\u001b[0m\n",
      "\u001b[34mCollecting itsdangerous>=2.0\u001b[0m\n",
      "\u001b[34mDownloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=3.6.0 in /opt/conda/lib/python3.8/site-packages (from flask->-r requirements.txt (line 12)) (4.11.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Werkzeug>=2.0 in /opt/conda/lib/python3.8/site-packages (from flask->-r requirements.txt (line 12)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cython>=0.24.0 in /opt/conda/lib/python3.8/site-packages (from pyworld->-r requirements.txt (line 17)) (0.29.28)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->flask->-r requirements.txt (line 12)) (3.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from Jinja2>=2.7->bokeh==1.4.0->-r requirements.txt (line 15)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.7.2->-r requirements.txt (line 6)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from soundfile>=0.9.0->librosa==0.7.2->-r requirements.txt (line 6)) (1.15.0)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 156.7/156.7 KB 32.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34mDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 107.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 KB 71.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (2.27.1)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.8/97.8 KB 22.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting regex\u001b[0m\n",
      "\u001b[34mDownloading regex-2022.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 764.9/764.9 KB 66.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting clldutils>=1.7.3\u001b[0m\n",
      "\u001b[34mDownloading clldutils-3.12.0-py2.py3-none-any.whl (197 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 197.6/197.6 KB 35.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting csvw>=1.5.6\u001b[0m\n",
      "\u001b[34mDownloading csvw-2.0.0-py2.py3-none-any.whl (35 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2->-r requirements.txt (line 6)) (2.21)\u001b[0m\n",
      "\u001b[34mCollecting colorlog\u001b[0m\n",
      "\u001b[34mDownloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.8/site-packages (from clldutils>=1.7.3->segments->phonemizer>=2.2.0->-r requirements.txt (line 7)) (0.8.9)\u001b[0m\n",
      "\u001b[34mCollecting rfc3986<2\u001b[0m\n",
      "\u001b[34mDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\u001b[0m\n",
      "\u001b[34mCollecting isodate\u001b[0m\n",
      "\u001b[34mDownloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.7/41.7 KB 3.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting uritemplate>=3.0.0\u001b[0m\n",
      "\u001b[34mDownloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 KB 28.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (1.26.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (2.0.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (2021.10.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34mDownloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.5/151.5 KB 35.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: librosa, bokeh, TTS, pyworld, audioread, resampy, termcolor\u001b[0m\n",
      "\u001b[34mBuilding wheel for librosa (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for librosa (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for librosa: filename=librosa-0.7.2-py3-none-any.whl size=1612900 sha256=b757dd4dbe2a3c9a7421a7db91972ba1b15ce486f5791c485f6e3f7b8296f3bf\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/11/f0/b0/a8f9944f274bbc0f0159f2268f43dadcfa1cfe50a9007d8e1f\u001b[0m\n",
      "\u001b[34mBuilding wheel for bokeh (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for bokeh (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for bokeh: filename=bokeh-1.4.0-py3-none-any.whl size=23689210 sha256=13c3915cbd2eb4d147ccc31f7384c8e9697a9ca068afb1d75fc3d140bd11eca9\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/4a/79/96/e953cfb5c24da5e5e03eb1ecb280ca88dce65661fb4d38c7b5\u001b[0m\n",
      "\u001b[34mBuilding wheel for TTS (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for TTS (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for TTS: filename=TTS-0.0.9.2-cp38-cp38-linux_x86_64.whl size=550925 sha256=7e56ab7739f4098358d12b459fb88563ea1fb0fa2ff4031ebeeca5441288d9ee\u001b[0m\n",
      "\u001b[34mStored in directory: /tmp/pip-ephem-wheel-cache-0o8yzfpm/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mBuilding wheel for pyworld (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for pyworld (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for pyworld: filename=pyworld-0.3.0-cp38-cp38-linux_x86_64.whl size=208612 sha256=5e8bfb1795e11cd0f3cd09b252260138f11a960eca7c602a51627a9cca0eded0\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/b7/9d/77/c12111ca99a5a889f7b3a44b55308f7bd230ea9dbaa2a99613\u001b[0m\n",
      "\u001b[34mBuilding wheel for audioread (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for audioread (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23153 sha256=ac913b932bafc728e84c7eb6ff3b449f8a854dd4ef9eac34483d5a5e954c25f3\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/49/5a/e4/df590783499a992a88de6c0898991d1167453a3196d0d1eeb7\u001b[0m\n",
      "\u001b[34mBuilding wheel for resampy (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for resampy (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320732 sha256=85f27d8df6dc6b711351f04b1c37aec72cab6b833788558c7e773252c06e2dc8\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/6f/d1/5d/f13da53b1dcbc2624ff548456c9ffb526c914f53c12c318bb4\u001b[0m\n",
      "\u001b[34mBuilding wheel for termcolor (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for termcolor (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=1590dd1e4235ef9072a40ded9c9705c3950882cb2a6c21dcb2d71f1af90d0c1a\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\u001b[0m\n",
      "\u001b[34mSuccessfully built librosa bokeh TTS pyworld audioread resampy termcolor\u001b[0m\n",
      "\u001b[34mInstalling collected packages: unidecode, termcolor, tensorflow-estimator, tensorboard-plugin-wit, rfc3986, llvmlite, dlinfo, audioread, wrapt, uritemplate, tensorboard-data-server, regex, pysbd, pyasn1-modules, oauthlib, numpy, itsdangerous, isodate, inflect, grpcio, gast, colorlog, cachetools, astunparse, absl-py, tensorboardX, soundfile, requests-oauthlib, pyworld, opt-einsum, numba, markdown, keras-preprocessing, h5py, google-auth, flask, csvw, bokeh, resampy, google-auth-oauthlib, clldutils, tensorboard, segments, librosa, tensorflow, phonemizer, TTS\u001b[0m\n",
      "\u001b[34mAttempting uninstall: llvmlite\u001b[0m\n",
      "\u001b[34mFound existing installation: llvmlite 0.36.0\u001b[0m\n",
      "\u001b[34mUninstalling llvmlite-0.36.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled llvmlite-0.36.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: numpy\u001b[0m\n",
      "\u001b[34mFound existing installation: numpy 1.22.2\u001b[0m\n",
      "\u001b[34mUninstalling numpy-1.22.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled numpy-1.22.2\u001b[0m\n",
      "\u001b[34mAttempting uninstall: numba\u001b[0m\n",
      "\u001b[34mFound existing installation: numba 0.53.1\u001b[0m\n",
      "\u001b[34mUninstalling numba-0.53.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled numba-0.53.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: h5py\u001b[0m\n",
      "\u001b[34mFound existing installation: h5py 3.6.0\u001b[0m\n",
      "\u001b[34mUninstalling h5py-3.6.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled h5py-3.6.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: bokeh\u001b[0m\n",
      "\u001b[34mFound existing installation: bokeh 2.4.2\u001b[0m\n",
      "\u001b[34mUninstalling bokeh-2.4.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled bokeh-2.4.2\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mpandas 1.4.2 requires numpy>=1.18.5, but you have numpy 1.17.5 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed TTS-0.0.9.2 absl-py-1.1.0 astunparse-1.6.3 audioread-2.1.9 bokeh-1.4.0 cachetools-5.2.0 clldutils-3.12.0 colorlog-6.6.0 csvw-2.0.0 dlinfo-1.2.1 flask-2.1.2 gast-0.3.3 google-auth-2.6.6 google-auth-oauthlib-0.4.6 grpcio-1.46.3 h5py-2.10.0 inflect-5.6.0 isodate-0.6.1 itsdangerous-2.1.2 keras-preprocessing-1.1.2 librosa-0.7.2 llvmlite-0.31.0 markdown-3.3.7 numba-0.48.0 numpy-1.17.5 oauthlib-3.2.0 opt-einsum-3.3.0 phonemizer-3.2.0 pyasn1-modules-0.2.8 pysbd-0.3.4 pyworld-0.3.0 regex-2022.6.2 requests-oauthlib-1.3.1 resampy-0.2.2 rfc3986-1.5.0 segments-2.2.0 soundfile-0.10.3.post1 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorboardX-2.5.1 tensorflow-2.3.1 tensorflow-estimator-2.3.0 termcolor-1.1.0 unidecode-0.4.20 uritemplate-4.1.1 wrapt-1.14.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-06-07 09:51:15,933 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-07 09:51:15,943 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-07 09:51:15,952 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-07 09:51:15,960 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config_path\": \"./config.json\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-06-07-09-44-11-151\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-082780074557/pytorch-training-2022-06-07-09-44-11-151/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_tacotron\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_tacotron.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"config_path\":\"./config.json\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_tacotron.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_tacotron\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-082780074557/pytorch-training-2022-06-07-09-44-11-151/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config_path\":\"./config.json\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-06-07-09-44-11-151\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-082780074557/pytorch-training-2022-06-07-09-44-11-151/source/sourcedir.tar.gz\",\"module_name\":\"train_tacotron\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_tacotron.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--config_path\",\"./config.json\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_CONFIG_PATH=./config.json\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220430-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m train_tacotron --config_path ./config.json\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mBuilding dependency tree...\u001b[0m\n",
      "\u001b[34mReading state information...\u001b[0m\n",
      "\u001b[34mE: Unable to locate package libsndfile1-dev\u001b[0m\n",
      "\u001b[34m2022-06-07 09:51:17.945504: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib:/opt/conda/lib:/home/.openmpi/lib/\u001b[0m\n",
      "\u001b[34m2022-06-07 09:51:17.945531: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\u001b[0m\n",
      "\u001b[34mreturn _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/train_tacotron.py\", line 22, in <module>\n",
      "    from TTS.tts.utils.synthesis import synthesis\n",
      "  File \"/opt/ml/code/TTS/tts/utils/synthesis.py\", line 4, in <module>\u001b[0m\n",
      "\u001b[34mimport tensorflow as tf\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/__init__.py\", line 41, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/python/__init__.py\", line 47, in <module>\u001b[0m\n",
      "\u001b[34mfrom tensorflow.python import keras\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py\", line 27, in <module>\u001b[0m\n",
      "\u001b[34mfrom tensorflow.python.keras import models\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/models.py\", line 26, in <module>\n",
      "    from tensorflow.python.keras.engine import functional\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\", line 38, in <module>\n",
      "    from tensorflow.python.keras.engine import training as training_lib\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 50, in <module>\n",
      "    from tensorflow.python.keras.engine import data_adapter\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 60, in <module>\u001b[0m\n",
      "\u001b[34mimport pandas as pd  # pylint: disable=g-import-not-at-top\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pandas/__init__.py\", line 22, in <module>\u001b[0m\n",
      "\u001b[34mfrom pandas.compat import is_numpy_dev as _is_numpy_dev\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pandas/compat/__init__.py\", line 14, in <module>\u001b[0m\n",
      "\u001b[34mfrom pandas._typing import F\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pandas/_typing.py\", line 120, in <module>\u001b[0m\n",
      "\u001b[34mnp.random.BitGenerator,\u001b[0m\n",
      "\u001b[34mAttributeError: module 'numpy.random' has no attribute 'BitGenerator'\u001b[0m\n",
      "\u001b[34m2022-06-07 09:51:18,754 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2022-06-07 09:51:18,754 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"AttributeError: module 'numpy.random' has no attribute 'BitGenerator'\u001b[0m\n",
      "\u001b[34m\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.8 -m train_tacotron --config_path ./config.json\"\u001b[0m\n",
      "\u001b[34m2022-06-07 09:51:18,754 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2022-06-07 09:51:38 Uploading - Uploading generated training model\n",
      "2022-06-07 09:51:38 Failed - Training job failed\n",
      "ProfilerReport-1654595213: NoIssuesFound\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-training-2022-06-07-09-44-11-151: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"AttributeError: module 'numpy.random' has no attribute 'BitGenerator'\n\"\nCommand \"/opt/conda/bin/python3.8 -m train_tacotron --config_path ./config.json\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-daf073144adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                            \u001b[0;31m#)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mpytorch_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# pour le training il faut ajouter des choses au fichier d'install requirements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    951\u001b[0m                     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m                     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingInput\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m                 \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileSystemInput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0mconfiguration\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m                     \u001b[0ma\u001b[0m \u001b[0mfile\u001b[0m \u001b[0msystem\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msource\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mprovide\u001b[0m \u001b[0madditional\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwell\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                     \u001b[0mthe\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1943\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1944\u001b[0;31m             \u001b[0mestimator\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEstimator\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1945\u001b[0m             \u001b[0mprofiler_rule_configs\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprofiler\u001b[0m \u001b[0mrule\u001b[0m \u001b[0mconfigurations\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m                 \u001b[0mupdated\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3751\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3752\u001b[0m         \u001b[0;31m# Notes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3753\u001b[0;31m         \u001b[0;31m# - The JOB_COMPLETE state forces us to do an extra pause and read any items that got to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3754\u001b[0m         \u001b[0;31m#   Cloudwatch after the job was marked complete.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3755\u001b[0m         \u001b[0mlast_describe_job_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3299\u001b[0m             \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnexpectedStatusException\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0mjob\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m         \"\"\"\n\u001b[0;32m-> 3301\u001b[0;31m         \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wait_until\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_transform_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TransformJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job pytorch-training-2022-06-07-09-44-11-151: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"AttributeError: module 'numpy.random' has no attribute 'BitGenerator'\n\"\nCommand \"/opt/conda/bin/python3.8 -m train_tacotron --config_path ./config.json\", exit code: 1"
     ]
    }
   ],
   "source": [
    "\n",
    "ROLE = get_execution_role()\n",
    "INSTANCE = 'ml.m5.4xlarge'\n",
    "\n",
    "config = \"./config.json\"\n",
    "pytorch_estimator = PyTorch(entry_point='train_tacotron.py',\n",
    "                            source_dir= \"./\",\n",
    "                            framework_version=\"1.11.0\",\n",
    "                            py_version=\"py38\",\n",
    "                            instance_type=INSTANCE,\n",
    "                            instance_count=1,\n",
    "                            role = ROLE,\n",
    "                            hyperparameters = {'config_path' : config}\n",
    "                            )\n",
    "\n",
    "pytorch_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using the extended docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test avec image rmreq\n",
    "\n",
    "ROLE = get_execution_role()\n",
    "INSTANCE = 'ml.m5.12xlarge'\n",
    "\n",
    "custom_docker_image = \"082780074557.dkr.ecr.eu-west-1.amazonaws.com/extend-container-tts:rmreq\"\n",
    "config = \"config2.json\"\n",
    "pytorch_estimator = PyTorch(entry_point='train_tacotron.py',\n",
    "                            source_dir=\"./\",\n",
    "                            #framework_version=\"1.7.1\",\n",
    "                            #py_version=\"py3\",\n",
    "                            image_uri=custom_docker_image,\n",
    "                            instance_type=INSTANCE,\n",
    "                            instance_count=1,\n",
    "                            role = ROLE,\n",
    "                            hyperparameters = {'config_path' : config}\n",
    "                           )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/pytorch-1.10-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
